# ============================================================================
# AI Provider API Keys
# ============================================================================
# Configure one or more AI providers for text generation
# IMPORTANT: Keep these secret! Never commit to git.

# OpenAI API (gpt-3.5-turbo, gpt-4, gpt-4o)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# DeepSeek API (deepseek-chat) - 60-70% cheaper than OpenAI
# Get your API key from: https://platform.deepseek.com/api_keys
# Cost: ~$0.27/M input tokens, ~$1.10/M output tokens
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Anthropic Claude API (claude-3-5-sonnet, claude-sonnet-4)
# Get your API key from: https://console.anthropic.com/settings/keys
# Cost: ~$3/M input tokens, ~$15/M output tokens
# Best for complex documents and large outputs
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API (gemini-2.0-flash-exp) - For medium documents and PDF extraction fallback
# Get your API key from: https://aistudio.google.com/apikey
# Cost: ~$0.35/M input tokens (Gemini 2.0 Flash)
# 2M token context window (vs 128K for GPT-3.5, 200K for Claude)
#
# TWO USE CASES:
# 1. PDF Extraction Fallback (with built-in OCR):
#    - Automatically used for medium files (10-20MB) - more reliable with OCR
#    - Used as fallback when pdf-parse and PyMuPDF fail (for small files <15MB)
#    - Handles scanned PDFs with built-in OCR
#    - NOTE: Gemini API has ~20MB file size limit for PDF uploads
# 2. RAG Queries for Large Documents:
#    - Processes entire document at once, no chunking needed
#    - Automatically used for documents > 500K characters (configurable)
#
# IMPORTANT: Optional but highly recommended for scanned PDFs and complex documents
GEMINI_API_KEY=your_gemini_api_key_here

# Gemini RAG threshold (in characters)
# Documents with more characters than this will use Gemini's 2M token context
# Documents below will use ChromaDB vector search for cost optimization
# Default: 500,000 characters (~500KB text, ~125K tokens, ~200 pages)
# Adjust based on your typical document sizes and cost preferences
# Examples:
#   100,000  = Use Gemini for docs > 100K chars (~40 pages)
#   500,000  = Use Gemini for docs > 500K chars (~200 pages) [DEFAULT]
#   1,000,000 = Use Gemini for docs > 1M chars (~400 pages)
GEMINI_THRESHOLD_CHARS=500000

# Lemonfox.ai TTS API (Text-to-Speech for podcasts)
# Get your API key from: https://www.lemonfox.ai/account/api-keys
# Cost: $2.50 per 1M characters (83% cheaper than OpenAI TTS!)
# Supports 8 languages: en-us, en-gb, ja, zh, es, fr, hi, it, pt-br
# 50+ natural-sounding voices available
LEMONFOX_API_KEY=your_lemonfox_api_key_here

# YouTube Data API v3 (for Video Learning feature)
# Get your API key from: https://console.cloud.google.com/apis/credentials
# Required for video search and metadata extraction
# Free tier: 10,000 units/day (1 search = 100 units, 100 searches/day)
# Setup instructions:
# 1. Create/select a project in Google Cloud Console
# 2. Enable YouTube Data API v3
# 3. Create an API key
# 4. (Optional) Restrict key to YouTube Data API v3 for security
YOUTUBE_API_KEY=your_youtube_api_key_here

# Google OAuth (for Google Docs import and Calendar sync)
# Get credentials from: https://console.cloud.google.com/apis/credentials
# Setup instructions:
# 1. Create/select a project in Google Cloud Console
# 2. Enable Google Docs API and Google Calendar API
# 3. Create OAuth 2.0 Client ID (Web application)
# 4. Add authorized redirect URI: http://localhost:3000/api/google/callback (dev)
#    and https://yourdomain.com/api/google/callback (production)
# 5. Copy Client ID and Client Secret here
GOOGLE_CLIENT_ID=your_google_client_id_here
GOOGLE_CLIENT_SECRET=your_google_client_secret_here

# ============================================================================
# Supabase Configuration
# ============================================================================
# Database and storage backend
# Get these from: https://app.supabase.com/project/_/settings/api

# Public URL (safe to expose to client)
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url

# Anon key (safe to expose to client, used for RLS)
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

# Service role key (NEVER expose to client! Server-side only)
# Has admin privileges, bypasses RLS
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# ============================================================================
# Clerk Authentication
# ============================================================================
# User authentication and management
# Get these from: https://dashboard.clerk.com

# Publishable key (safe to expose to client)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key

# Secret key (server-side only)
CLERK_SECRET_KEY=your_clerk_secret_key

# Auth flow URLs (customize as needed)
NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in
NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up
NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=/dashboard
NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=/dashboard

# ============================================================================
# Email Service (REQUIRED for transactional emails)
# ============================================================================
# Resend - Modern email API for developers
# Get your API key from: https://resend.com/api-keys
# Free tier: 100 emails/day, 3,000 emails/month
# Paid: $20/month for 50,000 emails/month
#
# Used for:
# - Welcome emails (hello@synaptic.study)
# - Subscription confirmations (hello@synaptic.study)
# - Payment receipts (hello@synaptic.study)
# - Payment failure alerts (support@synaptic.study)
# - Usage limit warnings (hello@synaptic.study)
# - Study reminders (hello@synaptic.study)
#
# Setup instructions:
# 1. Sign up at https://resend.com
# 2. Verify your domain (synaptic.study) by adding DNS records
# 3. Create an API key
# 4. Add the API key below
#
# Domain verification (add these DNS records to synaptic.study):
# - TXT record for domain verification
# - TXT record for SPF: "v=spf1 include:resend.com ~all"
# - CNAME record for DKIM
#
# IMPORTANT: Emails will not send until domain is verified!

# Resend API key (server-side only)
RESEND_API_KEY=your_resend_api_key_here

# ============================================================================
# Stripe Configuration (Optional - for monetization)
# ============================================================================
# Payment processing and subscriptions
# Get these from: https://dashboard.stripe.com/apikeys

# Publishable key (safe to expose to client)
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=your_stripe_publishable_key

# Secret key (server-side only)
STRIPE_SECRET_KEY=your_stripe_secret_key

# Webhook secret (for validating Stripe webhook events)
# Get from: https://dashboard.stripe.com/webhooks
STRIPE_WEBHOOK_SECRET=your_stripe_webhook_secret

# ============================================================================
# Sentry Error Monitoring (RECOMMENDED for production)
# ============================================================================
# Error tracking and performance monitoring
# Get these from: https://sentry.io
# Free tier: 5,000 events/month
# Team tier (recommended): $26/month for 50,000 events/month
# Setup guide: See docs/SENTRY-SETUP.md for complete instructions
#
# IMPORTANT: Required for Admin Dashboard observability features

# DSN for error reporting (safe to expose to client)
NEXT_PUBLIC_SENTRY_DSN=your_sentry_dsn_here
SENTRY_DSN=your_sentry_dsn_here

# Organization and project (for source maps)
SENTRY_ORG=your_sentry_org
SENTRY_PROJECT=your_sentry_project

# Auth token for uploading source maps (server-side only)
SENTRY_AUTH_TOKEN=your_sentry_auth_token

# Performance monitoring settings (optional, defaults shown)
# SENTRY_TRACES_SAMPLE_RATE=0.1  # Sample 10% of transactions in production
# SENTRY_PROFILES_SAMPLE_RATE=0.1  # Profile 10% of transactions

# ============================================================================
# Upstash Redis (Optional - for distributed rate limiting)
# ============================================================================
# Serverless Redis for rate limiting across multiple instances
# Get these from: https://console.upstash.com
# Free tier: 10,000 commands/day

# Only needed if you want distributed rate limiting
# Otherwise, in-memory rate limiting will be used (resets on server restart)
# UPSTASH_REDIS_REST_URL=your_upstash_redis_url
# UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token

# ============================================================================
# Cloudflare R2 Storage (For large file uploads - 500MB+ textbooks)
# ============================================================================
# S3-compatible object storage with zero egress fees
# Get these from: https://dash.cloudflare.com/r2
# Cost: $0.015/GB storage, $0 egress (vs AWS S3: $0.023/GB + $0.09/GB egress)
#
# Setup instructions:
# 1. Create a Cloudflare account and navigate to R2
# 2. Create a new R2 bucket (e.g., "synaptic-documents")
# 3. Go to "Manage R2 API Tokens" and create a token with read/write permissions
# 4. Copy the Access Key ID, Secret Access Key, and endpoint URL below
#
# IMPORTANT: For large documents (500MB+ textbooks), R2 is REQUIRED
# - Stores files efficiently without size limits
# - Zero egress fees save ~90% on bandwidth costs
# - Works seamlessly with RAG (Retrieval-Augmented Generation)

# R2 endpoint URL (format: https://<account-id>.r2.cloudflarestorage.com)
R2_ENDPOINT=your_r2_endpoint_url_here

# R2 access credentials (from API token)
R2_ACCESS_KEY_ID=your_r2_access_key_id_here
R2_SECRET_ACCESS_KEY=your_r2_secret_access_key_here

# R2 bucket name (the bucket you created for document storage)
R2_BUCKET_NAME=synaptic-documents

# Public URL for accessing files (optional - if bucket is public)
# Format: https://pub-<id>.r2.dev or custom domain
R2_PUBLIC_URL=your_r2_public_url_here

# ============================================================================
# ChromaDB Vector Database (For RAG - Retrieval-Augmented Generation)
# ============================================================================
# Vector database for semantic search on large documents
# Enables intelligent Q&A, flashcard generation, and chat on 500MB+ textbooks
#
# Setup instructions:
# 1. For development: Run ChromaDB locally with Docker:
#    docker run -d -p 8000:8000 chromadb/chroma
# 2. For production: Use hosted ChromaDB or deploy your own instance
# 3. Update CHROMA_URL to point to your ChromaDB instance
#
# Why ChromaDB?
# - Free and open-source
# - Perfect for prototyping RAG systems
# - Easy migration to Pinecone for production scale
# - Supports OpenAI embeddings (text-embedding-3-small)

# ChromaDB URL (default: http://localhost:8000 for Docker)
CHROMA_URL=http://localhost:8000

# ============================================================================
# App Configuration
# ============================================================================

# App URL (update for production)
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Environment (development | production | test)
NODE_ENV=development

# ============================================================================
# Google Calendar Integration (Optional)
# ============================================================================
# Enable importing events from Google Calendar
# Get OAuth credentials from: https://console.cloud.google.com/apis/credentials
#
# Setup instructions:
# 1. Create a project in Google Cloud Console
# 2. Enable Google Calendar API
# 3. Create OAuth 2.0 credentials (Web application)
# 4. Add authorized redirect URI: {NEXT_PUBLIC_APP_URL}/api/integrations/google-calendar/callback
# 5. Copy the Client ID and Client Secret below

# Google OAuth Client ID (safe to expose)
GOOGLE_CLIENT_ID=your_google_client_id_here

# Google OAuth Client Secret (server-side only)
GOOGLE_CLIENT_SECRET=your_google_client_secret_here

# OAuth Redirect URI (should match NEXT_PUBLIC_APP_URL + callback path)
# GOOGLE_REDIRECT_URI=http://localhost:3000/api/integrations/google-calendar/callback

# ============================================================================
# AI Provider Selection (Optional)
# ============================================================================
# Override which AI provider to use for each feature
# Options: openai, deepseek, anthropic
# If not set, intelligent defaults are used:
#  - Mind maps: deepseek (simple/moderate docs) or anthropic (complex docs)
#  - Podcast scripts: deepseek (cost-effective)
#  - Flashcards: openai (existing implementation)
#  - Chat: openai (existing implementation)

# Mind map generation provider
# MINDMAP_PROVIDER=deepseek

# Podcast script generation provider (audio TTS always uses OpenAI)
# PODCAST_SCRIPT_PROVIDER=deepseek

# Flashcard generation provider (optional override)
# FLASHCARD_PROVIDER=openai

# Document chat provider (optional override)
# CHAT_PROVIDER=openai

# ============================================================================
# Optional: Feature Flags
# ============================================================================

# Enable/disable features for testing
# NEXT_PUBLIC_ENABLE_PODCAST=true
# NEXT_PUBLIC_ENABLE_MINDMAP=true
# NEXT_PUBLIC_ENABLE_URL_IMPORT=true

# ============================================================================
# Admin Dashboard Configuration (Phase 0)
# ============================================================================
# Controls access to admin dashboard at /admin
# IMPORTANT: Only enable after setting up Clerk admin roles

# Enable admin dashboard feature
NEXT_PUBLIC_ENABLE_ADMIN_DASHBOARD=false

# Admin email whitelist (comma-separated, optional additional security)
# Only these emails can access admin routes even with admin role
# Leave empty to rely solely on Clerk roles
ADMIN_EMAIL_WHITELIST=

# Admin session timeout (in minutes, default: 60)
# ADMIN_SESSION_TIMEOUT=60

# ============================================================================
# Optional: Cost Controls
# ============================================================================

# Maximum monthly OpenAI spend (in USD)
# The app will stop making requests after this limit
# MAX_MONTHLY_OPENAI_SPEND=100

# Maximum cost per request (in USD)
# Requests exceeding this will be rejected
# MAX_COST_PER_REQUEST=1.00

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
#
# 1. Copy this file to .env.local
#    $ cp .env.example .env.local
#
# 2. Fill in all required values (marked with your_*_here)
#
# 3. Never commit .env.local to git (it's in .gitignore)
#
# 4. For production deployment:
#    - Use environment variable management from your hosting provider
#    - Vercel: https://vercel.com/docs/concepts/projects/environment-variables
#    - Set NODE_ENV=production
#    - Update NEXT_PUBLIC_APP_URL to your production domain
#
# ============================================================================

# ============================================================================
# Study Buddy Feature Flags (Phase 1A - Context Awareness)
# ============================================================================
# These flags enable enhanced Study Buddy capabilities with zero risk deployment
# Both flags are DISABLED by default for safety - enable after testing

# Date/Time Awareness
# Enables Study Buddy to know current date, time, and day of week
# Use cases: "study for tomorrow's exam", "what's due this week", time-based planning
# Default: false (disabled)
# Set to: true (to enable)
STUDY_BUDDY_DATE_TIME_AWARE=false

# Document Access
# Enables Study Buddy to see user's uploaded documents and reference them
# Shows list of recent documents in Study Buddy's context
# Future enhancement: Will enable RAG search through document content
# Default: false (disabled)
# Set to: true (to enable)
STUDY_BUDDY_DOCUMENT_ACCESS=false

# Deployment Strategy:
# Week 1: Set STUDY_BUDDY_DATE_TIME_AWARE=true, monitor for 48 hours
# Week 2: Set STUDY_BUDDY_DOCUMENT_ACCESS=true, monitor for 48 hours
# Rollback: Set to false if any issues arise
# ============================================================================
